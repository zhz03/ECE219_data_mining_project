{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68d78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.cluster import contingency_matrix, homogeneity_score, completeness_score, adjusted_rand_score, adjusted_mutual_info_score, v_measure_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "## Import libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('stopwords' )\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716a90ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, json, datetime, pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from textblob import TextBlob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2849c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import datetime\n",
    "\n",
    "pst_tz = pytz.timezone('America/Los_Angeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3cf117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/13/2022 03:39:25 - INFO - happytransformer.happy_transformer -   Using model: cuda\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextClassification\n",
    "happy_tc = HappyTextClassification(model_type=\"DISTILBERT\", \n",
    "                                       model_name=\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a169f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task='text2text-generation', model='facebook/m2m100_418M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e9696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_sentiment(tweet):\n",
    "    \n",
    "    result = happy_tc.classify_text(tweet)\n",
    "    if result.label == 'NEGATIVE':\n",
    "        return -1, -result.score\n",
    "    else:\n",
    "        return 1, result.score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9fb1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_and_transformer_sentiment(tweet):\n",
    "    \n",
    "    tweet = pipe(tweet, forced_bos_token_id=pipe.tokenizer.get_lang_id(lang='en'))\n",
    "    tweet = tweet[0]['generated_text']\n",
    "    result = happy_tc.classify_text(tweet)\n",
    "    if result.label == 'NEGATIVE':\n",
    "        return -1, -result.score\n",
    "    else:\n",
    "        return 1, result.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695aaf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72def57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(text):\n",
    "    with open(text+'.txt', 'r',encoding=\"utf8\") as f:\n",
    "        retweet_count, fav_count, followers, place, title, time = [],[],[],[],[],[]\n",
    "        sentiment_polarity, sentiment_score = [], []\n",
    "        pst_tz = pytz.timezone('US/Pacific') \n",
    "        for line in f:\n",
    "            tweet = json.loads(line)\n",
    "            title.append(tweet['title'])\n",
    "            retweet_count.append(tweet['metrics']['citations']['total']) \n",
    "            fav_count.append(tweet['tweet']['favorite_count'])\n",
    "            followers.append(tweet['author']['followers'])\n",
    "            time.append(datetime.datetime.fromtimestamp(tweet['citation_date'], pst_tz))\n",
    "            place.append(tweet['tweet']['user']['location'])\n",
    "            cleaned_tweet = clean_tweet(tweet['title'])\n",
    "            if not tweet['tweet']['lang'] == 'en':\n",
    "                senti_polarity, senti_score = translate_and_transformer_sentiment(cleaned_tweet)\n",
    "                sentiment_polarity.append(senti_polarity)\n",
    "                sentiment_score.append(senti_score)\n",
    "            else:\n",
    "                senti_polarity, senti_score = transformer_sentiment(cleaned_tweet)\n",
    "                sentiment_polarity.append(senti_polarity)\n",
    "                sentiment_score.append(senti_score)\n",
    "            break\n",
    "    d = {'title':title, 'retweet_count':retweet_count, 'favourite_count': fav_count, 'followers':followers,\n",
    "         'time':time,'place':place, 'sentiment_polarity':sentiment_polarity, 'sentiment_score':sentiment_score}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f93df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
