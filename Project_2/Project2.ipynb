{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23c404f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories1 = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.ibm.pc.hardware' ]\n",
    "categories2 = [ 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train1 = fetch_20newsgroups(subset='train', categories=categories1, shuffle=True, random_state=42, remove=('headers', 'footers'))\n",
    "test1 = fetch_20newsgroups(subset='test', categories=categories1, shuffle=True, random_state=42, remove=('headers', 'footers'))\n",
    "train2 = fetch_20newsgroups(subset='train', categories=categories2, shuffle=True, random_state=42, remove=('headers', 'footers'))\n",
    "test2 = fetch_20newsgroups(subset='test', categories=categories2, shuffle=True, random_state=42, remove=('headers', 'footers'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5cd4b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.ibm.pc.hardware']\n",
      "['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
      "[2 1 2 ... 1 2 2]\n",
      "[0 3 0 ... 3 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(train1.target_names)\n",
    "print(train2.target_names)\n",
    "print(train1.target)\n",
    "print(train2.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52a07596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1_data = train1.data \n",
    "X_train2_data = train2.data\n",
    "y_train1 = list(train1.target)\n",
    "y_train2 = list(train2.target)\n",
    "# y_train = [0]*len(list(train1.target)) + [1]*len(list(train2.target))\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bec4d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1765, 8597)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words='english', min_df=3, max_df=0.7)\n",
    "X_train1_counts = count_vect.fit_transform(X_train1_data)\n",
    "X_train1_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2249335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2389, 10361)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2_counts = count_vect.fit_transform(X_train2_data)\n",
    "X_train2_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "103b6679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1765, 8597)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X_train1_tfidf = tfidf_transformer.fit_transform(X_train1_counts)\n",
    "print(X_train1_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a362be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2389, 10361)\n"
     ]
    }
   ],
   "source": [
    "X_train2_tfidf = tfidf_transformer.fit_transform(X_train2_counts)\n",
    "print(X_train2_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4be420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(max_iter=100, n_clusters=2, n_init=1)\n",
      "done in 0.026s\n",
      "\n",
      "Homogeneity: 0.080\n",
      "Completeness: 0.162\n",
      "V-measure: 0.107\n",
      "Adjusted Rand-Index: 0.076\n",
      "Silhouette Coefficient: 0.005\n",
      "Contingency matrix:\n",
      "[[545  39]\n",
      " [501  90]\n",
      " [307 283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "\n",
    "true_k = 2 \n",
    "\n",
    "km = KMeans(\n",
    "        n_clusters=true_k,\n",
    "        init=\"k-means++\",\n",
    "        max_iter=100,\n",
    "        n_init=1)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X_train1_tfidf)\n",
    "labels = y_train1\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\" % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "    % metrics.silhouette_score(X_train1_tfidf, km.labels_, sample_size=1000)\n",
    ")\n",
    "print(\"Contingency matrix:\")\n",
    "print(metrics.cluster.contingency_matrix(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d866f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(max_iter=100, n_clusters=2, n_init=1)\n",
      "done in 0.033s\n",
      "\n",
      "Homogeneity: 0.244\n",
      "Completeness: 0.537\n",
      "V-measure: 0.336\n",
      "Adjusted Rand-Index: 0.226\n",
      "Silhouette Coefficient: 0.005\n",
      "Contingency matrix:\n",
      "[[594   0]\n",
      " [597   1]\n",
      " [319 278]\n",
      " [104 496]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X_train2_tfidf)\n",
    "labels = y_train2\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\" % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\n",
    "    \"Silhouette Coefficient: %0.3f\"\n",
    "    % metrics.silhouette_score(X_train2_tfidf, km.labels_, sample_size=1000)\n",
    ")\n",
    "print(\"Contingency matrix:\")\n",
    "print(metrics.cluster.contingency_matrix(labels, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155ffff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
